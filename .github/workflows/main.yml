name: Main CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

jobs:
  # Linting and syntax checks
  lint:
    name: Lint and Syntax Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check shell script syntax
        run: |
          find scripts tests -name "*.sh" -type f | while read -r script; do
            echo "Checking: $script"
            if grep -qE "^@test|^#!/usr/bin/env bats|^#!/bin/bats" "$script"; then
              echo "Skipping BATS test file: $script"
              continue
            fi
            bash -n "$script" || exit 1
          done

      - name: Validate docker-compose.yml
        run: |
          if [ -f docker-compose.yml ]; then
            docker run --rm -v "$PWD:/data" -w /data \
              docker/compose:latest config --quiet
          fi

  # Python API tests
  python-tests:
    name: Python API Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
          cache-dependency-path: api/requirements.txt

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r api/requirements.txt
          pip install -r api/requirements-test.txt

      - name: Run API tests (parallel)
        timeout-minutes: 15
        env:
          TESTING: 'true'
          PYTEST_CURRENT_TEST: '1'
        run: |
          cd tests/api
          pytest -v -n auto \
            --cov=../../api \
            --cov-config=../../.coverage-config.ini \
            --cov-report=term-missing \
            --cov-report=html:htmlcov \
            --cov-report=json:coverage.json \
            --cov-report=xml:coverage.xml \
            --timeout=300 \
            --timeout-method=thread \
            -ra

      - name: Run performance tests
        run: |
          cd tests/api
          pytest -v -m performance || echo "Performance tests completed"

      - name: Run contract tests
        run: |
          cd tests/api
          pytest -v -m contract || echo "Contract tests completed"

      - name: Analyze coverage gaps
        run: |
          chmod +x scripts/analyze-coverage-gaps.sh
          ./scripts/analyze-coverage-gaps.sh analyze || echo "Coverage gap analysis completed"

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-reports
          path: |
            tests/api/coverage.json
            tests/api/coverage.xml
            tests/api/htmlcov/
            coverage-gaps.txt
          retention-days: 30

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./tests/api/coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  # Bash script tests
  bash-tests:
    name: Bash Script Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Cache BATS
        id: cache-bats
        uses: actions/cache@v4
        with:
          path: /usr/local/bin/bats
          key: bats-${{ runner.os }}-v1
          restore-keys: |
            bats-${{ runner.os }}-

      - name: Install BATS
        if: steps.cache-bats.outputs.cache-hit != 'true'
        run: |
          git clone --depth 1 https://github.com/bats-core/bats-core.git /tmp/bats
          sudo /tmp/bats/install.sh /usr/local

      - name: Run bash tests
        run: |
          chmod +x scripts/*.sh tests/**/*.sh
          ./scripts/run-tests.sh bash || true

  # Frontend tests (non-blocking)
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: 'npm'
          cache-dependency-path: web/package-lock.json

      - name: Install dependencies
        working-directory: web
        run: npm ci

      - name: Run Vitest tests
        working-directory: web
        run: npm test || true

  # Playwright tests (non-blocking)
  playwright-tests:
    name: Playwright Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: 'npm'
          cache-dependency-path: web/package-lock.json

      - name: Install dependencies
        working-directory: web
        run: npm ci

      - name: Install Playwright Browsers
        working-directory: web
        run: npx playwright install --with-deps

      - name: Run Playwright tests
        working-directory: web
        run: npx playwright test || true

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: web/playwright-report/
          retention-days: 30

  # Build Docker image
  build-docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [lint, python-tests, bash-tests]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            image=moby/buildkit:latest
            network=host

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: minecraft-server
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build Docker image (ARM64 for Raspberry Pi 5)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/arm64
          push: false
          load: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            MINECRAFT_VERSION=1.20.4
            BUILDKIT_INLINE_CACHE=1
          cache-from: |
            type=gha,scope=build-docker
            type=registry,ref=ghcr.io/${{ github.repository }}/minecraft-server:buildcache
          cache-to: |
            type=gha,mode=max,scope=build-docker
            type=registry,ref=ghcr.io/${{ github.repository }}/minecraft-server:buildcache,mode=max
          outputs: type=docker,dest=/tmp/image.tar

      - name: Inspect image
        run: |
          docker load -i /tmp/image.tar
          docker image inspect minecraft-server:latest --format='{{.Size}}' | \
            awk '{printf "Image size: %.2f MB\n", $1/1024/1024}'
          docker image inspect minecraft-server:latest --format='{{range .RootFS.Layers}}{{println .}}{{end}}' | wc -l | \
            awk '{print "Number of layers: " $1}'

  # Summary job
  summary:
    name: Pipeline Summary
    runs-on: ubuntu-latest
    needs: [lint, python-tests, bash-tests, frontend-tests, playwright-tests, build-docker]
    if: always()
    steps:
      - name: Check test results
        run: |
          echo "## Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lint | ${{ needs.lint.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Python Tests | ${{ needs.python-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Bash Tests | ${{ needs.bash-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.frontend-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Playwright Tests | ${{ needs.playwright-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Docker Build | ${{ needs.build-docker.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Testing Enhancements" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Parallel test execution enabled" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Performance tests included" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Contract tests included" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Coverage gap analysis included" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Multiple coverage report formats (HTML, JSON, XML)" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.lint.result }}" != "success" ] || \
             [ "${{ needs.python-tests.result }}" != "success" ] || \
             [ "${{ needs.bash-tests.result }}" != "success" ] || \
             [ "${{ needs.build-docker.result }}" != "success" ]; then
            echo "❌ Critical jobs failed!" >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "✅ All critical jobs passed!" >> $GITHUB_STEP_SUMMARY
          fi
